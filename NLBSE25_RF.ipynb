{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for language: java\n",
      "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n",
      "Best hyperparameters for java: {'bootstrap': True, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 300}\n",
      "Training for language: python\n",
      "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n",
      "Best hyperparameters for python: {'bootstrap': True, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Training for language: pharo\n",
      "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n",
      "Best hyperparameters for pharo: {'bootstrap': True, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Performance by category and language:\n",
      "   language                 category  precision  recall      f1\n",
      "0      java                  summary     0.8263  0.8105  0.8183\n",
      "1      java                Ownership     0.9565  0.9778  0.9670\n",
      "2      java                   Expand     0.8824  0.1471  0.2521\n",
      "3      java                    usage     0.8734  0.7680  0.8173\n",
      "4      java                  Pointer     0.7289  0.8913  0.8020\n",
      "5      java              deprecation     0.6667  0.4000  0.5000\n",
      "6      java                 rational     0.4762  0.1471  0.2247\n",
      "7    python                    Usage     0.8261  0.4711  0.6000\n",
      "8    python               Parameters     0.8318  0.6953  0.7574\n",
      "9    python         DevelopmentNotes     0.5385  0.1707  0.2593\n",
      "10   python                   Expand     0.8235  0.2188  0.3457\n",
      "11   python                  Summary     0.6857  0.5854  0.6316\n",
      "12    pharo  Keyimplementationpoints     0.5385  0.1628  0.2500\n",
      "13    pharo                  Example     0.7172  0.8739  0.7879\n",
      "14    pharo         Responsibilities     0.6667  0.0385  0.0727\n",
      "15    pharo          Classreferences     1.0000  0.2500  0.4000\n",
      "16    pharo                   Intent     0.7692  0.3333  0.4651\n",
      "17    pharo              Keymessages     0.7857  0.5116  0.6197\n",
      "18    pharo            Collaborators     0.0000  0.0000  0.0000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import tqdm as notebook_tqdm\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from datasets import load_dataset\n",
    "import nltk\n",
    "\n",
    "#nltk.download('stopwords')\n",
    "#nltk.download('wordnet')\n",
    "\n",
    "ds = load_dataset('NLBSE/nlbse25-code-comment-classification')\n",
    "\n",
    "langs = ['java', 'python', 'pharo']\n",
    "labels = {\n",
    "    'java': ['summary', 'Ownership', 'Expand', 'usage', 'Pointer', 'deprecation', 'rational'],\n",
    "    'python': ['Usage', 'Parameters', 'DevelopmentNotes', 'Expand', 'Summary'],\n",
    "    'pharo': ['Keyimplementationpoints', 'Example', 'Responsibilities', 'Classreferences', 'Intent', 'Keymessages', 'Collaborators']\n",
    "}\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_data(data):\n",
    "    df = pd.DataFrame(data)\n",
    "    cleaned_features = []\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        combined_text = f\"{row['comment_sentence']} {row['class']}\"\n",
    "        words = combined_text.split()\n",
    "        lemmatized_words = [lemmatizer.lemmatize(word) for word in words]\n",
    "        filtered_words = [word for word in lemmatized_words if word.lower() not in stop_words]\n",
    "        cleaned_features.append(' '.join(filtered_words))\n",
    "\n",
    "    target = np.array(df['labels'].tolist())\n",
    "    return cleaned_features, target\n",
    "\n",
    "results = []\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "for lang in langs:\n",
    "    print(f\"Training for language: {lang}\")\n",
    "\n",
    "    train_features, train_labels = preprocess_data(ds[f'{lang}_train'])\n",
    "    test_features, test_labels = preprocess_data(ds[f'{lang}_test'])\n",
    "\n",
    "    vectorizer = TfidfVectorizer(max_features=5000)\n",
    "    X_train = vectorizer.fit_transform(train_features)\n",
    "    X_test = vectorizer.transform(test_features)\n",
    "\n",
    "    rf = RandomForestClassifier()\n",
    "\n",
    "    grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2, scoring='accuracy')\n",
    "    grid_search.fit(X_train, train_labels)\n",
    "    print(f\"Best hyperparameters for {lang}: {grid_search.best_params_}\")\n",
    "\n",
    "    best_rf = grid_search.best_estimator_\n",
    "    y_pred = best_rf.predict(X_test)\n",
    "\n",
    "    for i, label in enumerate(labels[lang]):\n",
    "        precision = precision_score(test_labels[:, i], y_pred[:, i], zero_division=0)\n",
    "        recall = recall_score(test_labels[:, i], y_pred[:, i], zero_division=0)\n",
    "        f1 = f1_score(test_labels[:, i], y_pred[:, i], zero_division=0)\n",
    "        results.append({\n",
    "            'language': lang,\n",
    "            'category': label,\n",
    "            'precision': round(precision, 4),\n",
    "            'recall': round(recall, 4),\n",
    "            'f1': round(f1, 4)\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "print(\"Performance by category and language:\")\n",
    "print(results_df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
